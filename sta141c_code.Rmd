---
title: "STA141C Final Project"
author: "Ryan Cosgrove, Ravinit Chand, Eric Kye, Revanth Rao"
date: "2024-06-07"
output:
  pdf_document: default
  word_document: default
---
# Libraries ---------------------------------------------------------------

```{r}
library(tidyverse)
library(glmnet)
library(randomForest)
library(MASS)
library(corrplot)
library(pROC)
library(ROCR)
library(vtable)
library(Hmisc)
```
# Loading Data and Preprocessing

```{r}
weather = read.csv("/Users/eric/Documents/Classroom/23-24/3 Spring/STA141C/Project/weatherAUS.csv") 

weather = weather %>% mutate_at(c('WindGustDir', 'WindDir9am', 'WindDir3pm', 
                                  'RainToday', 'RainTomorrow'), as.factor)
weather$Year = as.integer(sapply(strsplit(weather[,1], "-"), getElement, 1))
weather_summary = summary(weather)

```
# Splitting Data and Removing Variables
```{r}
train_index = (weather$Year < 2013)
test_index = !train_index

train = weather[train_index, ]
test = weather[test_index, ]

```

# Remove columns
```{r}
train = train[, c(-1, -2, -8, -10, -11, -24)]
test = test[, c(-1, -2, -8, -10, -11, -24)]
weather = weather[, c(-1, -2, -8, -10, -11, -24)]
weather_plotting = weather[, c(-17, -18)]

```

# Remove NAs
```{r}

train = na.omit(train)
test = na.omit(test)
weather = na.omit(weather)
RainTom.test <- test$RainTomorrow
```


# Exploratory Data Analysis -----------------------------------------------
```{r, fig.width=12, fig.height=10}
st(weather) # Summary Statistics
corrplot(cor(weather[, c(-17, -18)]), method = "square") # Correlation plot

# Adjust margins and create histograms of predictor variables
par(mar = c(5, 4, 4, 2) + 0.1)
hist.data.frame(weather_plotting) # Histogram of the Predictor Variables
```

# GLM Model

```{r}
glm.fits <- glm(RainTomorrow ~ ., data = train, family = "binomial")
glm.fits
glm.probs <- predict(glm.fits, test, type = "response")
preds= prediction(glm.probs, RainTom.test)
prf = performance(preds, measure = "tpr", x.measure = "fpr")

glm.pred <- rep("No", length(glm.probs))
glm.pred[glm.probs > .5] <- "Yes"
table(glm.pred, RainTom.test)
mean(glm.pred == RainTom.test)
mean(glm.pred != RainTom.test)
```
# GLM plot
```{r}
plot(prf, col = 'red', main = 'ROC Curve for Logistic Regression')
```

# LDA Model
```{r}

lda.fit <- lda(RainTomorrow ~ ., data = train)
lda.fit
plot(lda.fit, ylab = "Frequency")

lda.pred <- predict(lda.fit, test)

lda.class <- lda.pred$class
table(lda.class, RainTom.test)
mean(lda.class == RainTom.test)

sum(lda.pred$posterior[, 1] >= .5)
sum(lda.pred$posterior[, 1] < .5)

lda.pred$posterior[1:20, 1]
lda.class[1:20]
sum(lda.pred$posterior[, 1] > .9)
```
# QDA Model
```{r}
qda.fit <- qda(RainTomorrow ~ ., data = train)
qda.fit
qda.class <- predict(qda.fit, test)$class
table(qda.class, RainTom.test)
mean(qda.class == RainTom.test)

# Recreate x and y after removing NA rows from train and test
x <- model.matrix(RainTomorrow ~ ., rbind(train, test))[,-1]
y <- as.numeric(rbind(train, test)$RainTomorrow) - 1

train_rows <- 1:nrow(train)
test_rows <- (nrow(train) + 1):nrow(x)
```
# Lasso Model
```{r}
lasso.fit <- cv.glmnet(x[train_rows, ], y[train_rows], family = "binomial", alpha = 1)
plot(lasso.fit)
lasso.pred <- predict(lasso.fit, s = "lambda.min", newx = x[test_rows, ], type = "class")
lasso.pred <- ifelse(lasso.pred == "1", "Yes", "No")
table(lasso.pred, RainTom.test)
mean(lasso.pred == RainTom.test)
lasso_coefficients <- predict(lasso.fit, type = "coefficients", s = "lambda.min") 
lasso_coefficients[lasso_coefficients != 0]
length(lasso_coefficients[lasso_coefficients != 0])
```
# Ridge Model
```{r}
ridge.fit <- cv.glmnet(x[train_rows, ], y[train_rows], family = "binomial", alpha = 0)
plot(ridge.fit)
ridge.pred <- predict(ridge.fit, s = "lambda.min", newx = x[test_rows, ], type = "class")
table(ridge.pred, RainTom.test)
mean(ridge.pred == RainTom.test)
ridge_coefficients <- predict(ridge.fit, type = "coefficients", s = "lambda.min") 
ridge_coefficients[ridge_coefficients != 0]
length(ridge_coefficients[ridge_coefficients != 0])
```
# Plots for Lasso and Ridge Model 
```{r}
par(mfrow = c(1, 2), mar = c(5, 4, 6, 2) + 0.1)
plot(lasso.fit, main = "Lasso Model")
plot(ridge.fit, main = "Ridge Model")
```

# Random Forest
```{r}
rf.fit <- randomForest(RainTomorrow ~ ., data = train, importance = TRUE)
rf.pred <- predict(rf.fit, newdata = test)
table(rf.pred, RainTom.test)
mean(rf.pred == RainTom.test)
```
# Random Forest Importance
```{r}
importance(rf.fit)
varImpPlot(rf.fit)
```
